{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "colab": {
      "name": "pooling_scaffold.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wpaHjZ36cWLE"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from numpy.random import seed\n",
        "import matplotlib.pyplot as plt\n",
        "from prettytable import PrettyTable\n",
        "from helper import get_data, plot_activation\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Dense,Conv2D,Dropout,Flatten,MaxPooling2D,AveragePooling2D\n",
        "\n",
        "# Set random seed\n",
        "seed(1)\n",
        "tf.random.set_seed(1)\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Svh9tCBDcWLF",
        "outputId": "24d507b4-e94b-4a5b-cab3-4f03ba0fcc24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Use the helper function get_data to get the train and \n",
        "# test MNIST dataset\n",
        "x_train, y_train, x_test, y_test = get_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "fUvb9ZTCcWLF"
      },
      "outputs": [],
      "source": [
        "# Setting the random seed\n",
        "seed(1)\n",
        "tf.random.set_seed(1)\n",
        "\n",
        "# Function to define the CNN model for MNIST classification\n",
        "def cnn_model(pool_type=\"no_pooling\"):\n",
        "\n",
        "  # Intialize a sequential model\n",
        "  model = Sequential(name=pool_type) \n",
        "\n",
        "  # Define the input shape \n",
        "  input_shape = (28, 28, 1)\n",
        "\n",
        "  # Add a convolutional layer with 28 filters, kernel size of 3,\n",
        "  # input_shape as input_shape defined above and tanh activation\n",
        "  model.add(Conv2D(28,3,1,padding='valid',input_shape=input_shape,activation='tanh'))\n",
        "\n",
        "  # Define size of the pooling operation\n",
        "  pool_size=(3,3)\n",
        "\n",
        "  # Add an average pooling layer with pool size value as defined \n",
        "  # above by pool_size\n",
        "  if pool_type==\"avg_pooling\":\n",
        "    model.add(AveragePooling2D(pool_size,padding='valid'))\n",
        "\n",
        "  # Add a max pooling layer based with pool size value as defined \n",
        "  # above by pool_size\n",
        "  if pool_type==\"max_pooling\":\n",
        "    model.add(MaxPooling2D(pool_size,padding='valid'))\n",
        "\n",
        "  # Add a flatten layer\n",
        "  model.add(Flatten())\n",
        "\n",
        "  # Add a dense layer with ReLU activation with 16 nodes\n",
        "  model.add(Dense(16,activation='ReLU'))\n",
        "\n",
        "  # Add a dropout layer with 0.3 as the dropout percentage\n",
        "  model.add(Dropout(0.3))\n",
        "\n",
        "  # Add an output layer with 10 nodes and softmax activation\n",
        "  model.add(Dense(10,activation='softmax'))\n",
        "\n",
        "  # Compile the model with adam optimizer, \n",
        "  # sparse_categorical_crossentropy as the loss \n",
        "  # and accuracy as the metric\n",
        "  opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "  model.compile(optimizer=opt,loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "  \n",
        "  # Fit the model on the train data with 8 epochs\n",
        "  model.fit(x_train , y_train , epochs= 8, verbose=0, \n",
        "            shuffle=False, workers=0, use_multiprocessing=False)\n",
        "\n",
        "  return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpAL-wCncWLG",
        "outputId": "6f6baeb6-a48d-492b-e55e-34f4abaf88fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 1s 7ms/step - loss: 0.4364 - accuracy: 0.8772\n",
            "The accuracy of the model with no pooling is 0.8772000074386597\n"
          ]
        }
      ],
      "source": [
        "### edTest(test_no_pool) ###\n",
        "# Call the cnn_model function with pool_type as no_pooling \n",
        "# to get the trained model without pooling\n",
        "model = cnn_model(pool_type=\"no_pooling\")\n",
        "\n",
        "# Evaluate on the test data\n",
        "no_pool_acc = model.evaluate(x_test, y_test)\n",
        "print(\"The accuracy of the model with no pooling is\", no_pool_acc[1])\n",
        "\n",
        "# Get the number of parameters of the network\n",
        "no_pool_params = model.count_params()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nusgluu-cWLG",
        "outputId": "2feac609-99b3-4507-9dce-4dc32df01241"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 1s 7ms/step - loss: 0.3424 - accuracy: 0.9028\n",
            "The accuracy of the model with average pooling is 0.9028000235557556\n"
          ]
        }
      ],
      "source": [
        "### edTest(test_avg_pool) ###\n",
        "# Call the cnn_model function with pool_type as avg_pooling \n",
        "# to get the trained model with avg pooling\n",
        "model = cnn_model(pool_type=\"avg_pooling\")\n",
        "\n",
        "# Evaluate on the test data\n",
        "avg_pool_acc = model.evaluate(x_test, y_test)\n",
        "print(\"The accuracy of the model with average pooling is\", avg_pool_acc[1])\n",
        "\n",
        "# Get the number of parameters of the network\n",
        "avg_pool_params = model.count_params()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62lwHhyncWLH",
        "outputId": "743ba34d-fd3f-4b3a-886a-ccb86721715b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 1s 6ms/step - loss: 0.1654 - accuracy: 0.9532\n",
            "The accuracy of the model with max pooling is 0.9531999826431274\n"
          ]
        }
      ],
      "source": [
        "### edTest(test_max_pool) ###\n",
        "# Call the cnn_model function with pool_type as max_pooling \n",
        "# to get the trained model with max pooling\n",
        "model = cnn_model(pool_type=\"max_pooling\")\n",
        "\n",
        "# Evaluate on the test data\n",
        "max_pool_acc = model.evaluate(x_test, y_test)\n",
        "print(\"The accuracy of the model with max pooling is\", max_pool_acc[1])\n",
        "\n",
        "# Get the number of parameters of the network\n",
        "max_pool_params = model.count_params()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Z1gEkvhcWLH"
      },
      "source": [
        "### ⏸ Based on the results seen here, which of the following is the most true?\n",
        "\n",
        "#### A. The average pooling provides no advantage over no pooling models.\n",
        "#### B. The no pooling model is more robust and reliable for all datasets.\n",
        "#### C. The max pooling and average pooling though have lower number of parameters takes longer time to train than the no pooling model.\n",
        "#### D. The max pooling model performs better as MNIST is made up of mostly edges and high contrasts which provide for max pooling to easily identify the sharp edges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "HHJW9FrScWLP"
      },
      "outputs": [],
      "source": [
        "### edTest(test_chow1) ###\n",
        "# Submit an answer choice as a string below (eg. if you choose option C, put 'C')\n",
        "answer1 = 'D'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4LI3vmVcWLP",
        "outputId": "93aa84fc-3f9a-4d8e-fe09-b87e46d5e6e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+---------------+-----------+----------------------+\n",
            "|    Model Type    | Test Accuracy | Test Loss | Number of Parameters |\n",
            "+------------------+---------------+-----------+----------------------+\n",
            "| Without pooling  |     0.8772    |   0.4364  |        303314        |\n",
            "| With avg pooling |     0.9028    |   0.3424  |        29138         |\n",
            "| With max pooling |     0.9532    |   0.1654  |        29138         |\n",
            "+------------------+---------------+-----------+----------------------+\n"
          ]
        }
      ],
      "source": [
        "### edTest(test_accuracy) ###\n",
        "# Display the models with their accuracy score and parameters \n",
        "table = PrettyTable()\n",
        "\n",
        "table.field_names = [\"Model Type\", \"Test Accuracy\", \"Test Loss\", \"Number of Parameters\"]\n",
        "table.add_row([\"Without pooling\", round(no_pool_acc[1],4), round(no_pool_acc[0],4), no_pool_params])\n",
        "table.add_row([\"With avg pooling\", round(avg_pool_acc[1],4), round(avg_pool_acc[0],4), avg_pool_params])\n",
        "table.add_row([\"With max pooling\", round(max_pool_acc[1],4), round(max_pool_acc[0],4), max_pool_params])\n",
        "print(table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGgX3RIkcWLP"
      },
      "source": [
        "### ⏸ How does the accuracy and loss of the model vary by increasing the pool_size to (5x5)? Why does this happen?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2qQhhbN4cWLQ"
      },
      "outputs": [],
      "source": [
        "### edTest(test_chow2) ###\n",
        "\n",
        "# Type your answer within in the quotes given\n",
        "answer2 = 'The accuracy decreasing because we are eliminating too many features. There are only 28*28\\\n",
        "            and we are reducing it by nearly 1/5 everytime. '"
      ]
    }
  ]
}