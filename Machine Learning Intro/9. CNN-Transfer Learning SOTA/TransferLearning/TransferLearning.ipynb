{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4,
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "\u003ca href=\"https://colab.research.google.com/drive/1ovkNuIpOxeJtgJCNDuMys0tzBoS2_9vA?usp=sharing``\" target=\"_blank\" \u003e\n",
                "  \u003cimg src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/\u003e\n",
                "\n",
                "**(Note: This notebook will not run on Ed. Please click the button above to run in Google Colab)**\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Importing necessary packages and libraries\n",
                "\n",
                "import tensorflow.keras as keras\n",
                "from tensorflow.keras import backend as K\n",
                "from tensorflow.keras.layers import Dense, Activation\n",
                "from tensorflow.keras.optimizers import Adam\n",
                "from tensorflow.keras.metrics import categorical_crossentropy\n",
                "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
                "from tensorflow.keras.preprocessing import image\n",
                "from tensorflow.keras.models import Model\n",
                "from tensorflow.keras.applications import imagenet_utils\n",
                "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D\n",
                "from tensorflow.keras.applications import MobileNet\n",
                "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
                "import numpy as np\n",
                "import os\n",
                "from IPython.display import Image\n",
                "from tensorflow.keras.optimizers import Adam\n",
                "import matplotlib.pyplot as plt\n",
                "import matplotlib.image as mpimg\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Helper code to get the image data and prepare .keras and data directory\n",
                "DATA_DIR = '.'\n",
                "\n",
                "if 'ED_USER_NAME' in os.environ:\n",
                "    !rm -rf .keras\n",
                "    !mkdir -p /tmp/keras\n",
                "    !ln -s /tmp/keras ~/.keras\n",
                "\n",
                "    DATA_DIR = '/course/data/SikhOrNot'\n",
                "else:\n",
                "    !gdown https://drive.google.com/uc?id=1ERbOnnrrpqXuPhin-7pPZdY04QlJqPVF\n",
                "    !unzip -qq SikhOrNot.zip"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Lets now use MobileNet as it is quite lightweight (17Mb), freeze the base layers and lets add and train the top few layers. Note only two classifiers."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Get dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_split) ###\n",
                "\n",
                "# Path of image data\n",
                "data_path = os.path.join(DATA_DIR, 'images/train')\n",
                "\n",
                "# Use the `ImageDataGenerator` function from keras to generate new images based on our existing ones\n",
                "# Mention the preprocessing function as mobilenet's preprocess_input and specify a validation split of 20%\n",
                "train_datagen=ImageDataGenerator(___) \n",
                "\n",
                "# Build your train_generator by specifying the directory using the data_path variable defined above\n",
                "# Mention target size as (224,224), color mode, class mode, batch_size, subset as 'training' and shuffle = True\n",
                "train_generator=train_datagen.flow_from_directory(___)\n",
                "\n",
                "# Build your validation_generator similar to the previous step \n",
                "# Specifying using the data_path variable defined above with subset as 'validation'\n",
                "validation_generator=train_datagen.flow_from_directory(___)\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Mobilenet plug and play"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Use the mobilenet architecture as a starting point for our base model \n",
                "\n",
                "# Import the mobilenet model with pre-trained imagenet weights\n",
                "# Discard the last 1000 neuron layer ie. the final fully connected layer\n",
                "base_model=MobileNet(___) "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "x=base_model.output\n",
                "\n",
                "x=GlobalAveragePooling2D()(x)\n",
                "\n",
                "# On top of mobile net, add a few dense layers with 'relu' activation\n",
                "\n",
                "# Using functional API, add a dense layer with 1024 neurons \n",
                "x=Dense(___)(x)\n",
                "\n",
                "# Add a dense layer with 512 neurons\n",
                "x=Dense(___)(x)\n",
                "\n",
                "# Add a final layer with 2 neurons and softmax activation \n",
                "preds=Dense(___)(x) \n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Using the functional API of keras, specify the input from the base model and the output as `preds` described above\n",
                "\n",
                "model=Model(___) #specify the inputs and outputs\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Lets check the model architecture"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_summary) ###\n",
                "\n",
                "# Look at the summary of your model\n",
                "model.___()\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We will use pre-trained weights as the model has been trained already on the Imagenet dataset. We ensure all the weights are non-trainable. We will only train the last few dense layers."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_layers) ###\n",
                "# For transfer learning, we need to freeze some layers. Below we freeze the first 10 layers\n",
                "\n",
                "# Freeze the first 10 layers of the network to be non-trainable\n",
                "for layer in model.layers[:10]:\n",
                "    ___\n",
                "    "
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now lets load the training data into the ImageDataGenerator. Specify path, and it automatically sends the data for training in batches, simplifying the code."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Compile the model. Now lets train it. Should take less than two minutes on a GTX1070 GPU."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Training the model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# We now train our model, but first we will compile it with an appropriate loss function and optimizer\n",
                "\n",
                "# Adam optimizer\n",
                "# loss function will be categorical crossentropy\n",
                "# evaluation metric will be accuracy\n",
                "\n",
                "model.compile(___)\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Fit the model using the step size for train and validation specified below\n",
                "# Given the limited resources, please restrict the number of epochs to less than 5\n",
                "\n",
                "step_size_train=train_generator.n//train_generator.batch_size\n",
                "step_size_validation=validation_generator.n//validation_generator.batch_size\n",
                "\n",
                "model.fit(___)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Model is now trained. Now lets test some independent input images to check the predictions."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Inference on unseen data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# A helper function that takes a standard image and converts it into a tensor that can be used by the model\n",
                "\n",
                "def load_image(img_path, show=False):\n",
                "\n",
                "    img = image.load_img(img_path, target_size=(224, 224))\n",
                "    img_tensor = image.img_to_array(img)                    # (height, width, channels)\n",
                "    img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n",
                "    img_tensor = preprocess_input(img_tensor)               # imshow expects values in the range [0, 1]\n",
                "\n",
                "    if show:\n",
                "        plt.imshow(img_tensor[0])                           \n",
                "        plt.axis('off')\n",
                "        plt.show()\n",
                "\n",
                "    return img_tensor"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# We specify the paths of the six images \n",
                "\n",
                "# First set of images\n",
                "img_path1 = os.path.join(DATA_DIR, 'images/test/hargun.jpeg')\n",
                "img_path2 = os.path.join(DATA_DIR, 'images/test/pavlos.jpeg')\n",
                "img_path3 = os.path.join(DATA_DIR, 'images/test/varshini.jpeg')\n",
                "\n",
                "\n",
                "# Second set of images\n",
                "img_path4 = os.path.join(DATA_DIR, 'images/test/arya.jpeg')\n",
                "img_path5 = os.path.join(DATA_DIR, 'images/test/punjabiPavlos.jpg')\n",
                "img_path6 = os.path.join(DATA_DIR, 'images/test/anusha.jpeg')\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Helper function that nicely predicts the class along with the input image\n",
                "\n",
                "def prediction(img_loc,ax):\n",
                "    new_image = load_image(img_loc)\n",
                "    pred = model.predict(new_image)\n",
                "    classmap = {v:k for k,v in (train_generator.class_indices).items()}\n",
                "    plot_img = mpimg.imread(img_loc);\n",
                "    ax.imshow(plot_img)\n",
                "    ax.set_title(f'Prediction: {classmap[pred.argmax(-1)[0]]} \\n (with confidence: {str(pred[0][pred.argmax(-1)][0])[:4]})'  ,fontsize=18)\n",
                "    ax.axis('off')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Make predictions on first set of images defined above that were never shown to the model before\n",
                "fig, axes = plt.subplots(1,3,figsize=(12,6))\n",
                "\n",
                "# Call the prediction function defined above for this\n",
                "# For each prediction mention the axes\n",
                "___\n",
                "___\n",
                "___\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Make predictions on second set of images defined above that were never shown to the model before\n",
                "fig, axes = plt.subplots(1,3,figsize=(12,6))\n",
                "\n",
                "# Call the prediction function defined above for this\n",
                "# For each prediction mention the axes\n",
                "___\n",
                "___\n",
                "___\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Mindchow üç≤\n",
                "\n",
                "Go back and change the number of trainable parameters. How does it affect your network performance?"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "*Your answer here*"
            ]
        }
    ]
}
