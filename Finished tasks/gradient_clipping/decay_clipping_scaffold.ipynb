{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3",
            "language": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4,
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "# Import necessary libraries\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "%matplotlib inline"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "# Function to compute response given predictor\n",
                "def f(x):\n",
                "    return np.cos(3*np.pi*x)/x"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "# Function to compute the derivative\n",
                "def der_f(x):\n",
                "    return -(3*np.pi*x*np.sin(3*np.pi*x)+np.cos(3*np.pi*x))/x**2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "# Helper function to get tangent points\n",
                "def get_tangent_line(x, x_range=.5):\n",
                "    y = f(x)\n",
                "    m = der_f(x)\n",
                "    x1, y1 = x, y\n",
                "    x = np.linspace(x1-x_range/2, x1+x_range/2, 50)\n",
                "    y = m*(x-x1)+y1\n",
                "    return x, y, m"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "# Helper function to plot the data\n",
                "def plot_it(cur_x, title='', ax=plt):\n",
                "    y = f(x)\n",
                "    ax.plot(x,y)\n",
                "    ax.scatter(cur_x, f(cur_x), c='r', s=80, alpha=1);\n",
                "    x_tan, y_tan, der = get_tangent_line(cur_x)\n",
                "    ax.plot(x_tan, y_tan, ls='--', c='r')\n",
                "    # Indicate when if our location is outside the x range\n",
                "    if cur_x \u003e x.max():\n",
                "        ax.axvline(x.max(), c='r', lw=3)\n",
                "        ax.arrow(x.max()/1.6, y.max()/2, x.max()/5, 0, color='r', head_width=.25)\n",
                "    if cur_x \u003c x.min():\n",
                "        ax.axvline(x.min(), c='r', lw=3)\n",
                "        ax.arrow(x.max()/2.5, y.max()/2, -x.max()/5, 0, color='r', head_width=.25)\n",
                "    ax.set_xlim(x.min(), x.max())\n",
                "    ax.set_ylim(-3.5, 3.5)\n",
                "    ax.set_title(title)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate 200 predictor data points between 0.07 and 3 using np.linspace\n",
                "x = ___\n",
                "\n",
                "# Get the response data from the predictor data by calling the function f \n",
                "y = ___\n",
                "\n",
                "# Helper code to plot the generated data\n",
                "fig, ax = plt.subplots(figsize=(8,6))\n",
                "plt.plot(x,y, linewidth=3, color='#F5B7B1')\n",
                "plt.xlim(x.min(), x.max());\n",
                "plt.xticks(fontsize=14)\n",
                "plt.yticks(fontsize=14)\n",
                "plt.xlabel('$x$', fontsize=16)\n",
                "plt.ylabel('$y$', fontsize=16)\n",
                "plt.grid(alpha=0.5)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "### edTest(test_clipping) ###\n",
                "\n",
                "# Function to perform clipping\n",
                "# This function should return the gradient with a magnitude\u003c=clip_threshold\n",
                "def clip(g, use_clip=0, clip_threshold=8):\n",
                "    \n",
                "    # Compare the absolute value of the gradient with the clip_threshold\n",
                "    if ___ and use_clip==1:\n",
                "        \n",
                "        # Compute the gradient based on the equation given\n",
                "        ___\n",
                "        \n",
                "    return g"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Function to perform gradient descent with clipping and plot it\n",
                "def gradient_descent(cur_x, learning_rate, epsilon, num_iter, clip_threshold, use_clip=0):\n",
                "    \n",
                "    # Plotting one panel per gradient descent iteration\n",
                "    fig, axs = plt.subplots(num_iter//3, 3, figsize=(15,6), sharey=True)\n",
                "\n",
                "    # To create sub-panels\n",
                "    for i, ax in enumerate(axs.ravel()):\n",
                "        plot_it(cur_x, title=f\"{i} step{'' if i == 1 else 's'}\", ax=ax)\n",
                "\n",
                "        # Store the current x value before change in a separate variable\n",
                "        prev_x = ___\n",
                "\n",
                "        # Get the derivative of cur_x using the function der_f\n",
                "        der_cur_x = ___\n",
                "\n",
                "        # Clip the gradient of the derivative of x by calling the \n",
                "        # clip function with use_clip and the clip_threshold as in \n",
                "        # the function definition \n",
                "        g = ___\n",
                "\n",
                "        # Update the x-value using the learning rate\n",
                "        cur_x = ___\n",
                "\n",
                "        # Stop algorithm if magnitude of change goes below epsilon\n",
                "        if np.abs(cur_x - prev_x) \u003c= epsilon: \n",
                "\n",
                "            # Hide unused subplots on convergence\n",
                "            for ax in axs.ravel()[i+1:]:\n",
                "                ax.axis('off') \n",
                "            break\n",
                "\n",
                "    plt.tight_layout()\n",
                "\n",
                "    if i == len(axs.ravel())-1:\n",
                "        print('Did not converge!')"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ‚è∏ Set the intial x value to 0.07, learning rate to 0.01, and epsilon to 0.025. With use_clip value as 0 perform gradient descent. What do you observe and why?\n",
                "\n",
                "#### A. There is no convergence visible because of high learning rate.\n",
                "#### B. There are 2 convergence points due to small decay rate.\n",
                "#### C. The first gradient is very large and hence takes us away from the region of interest.\n",
                "#### D. There is no convergence visible because the epsilon is extremely low."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_chow1) ###\n",
                "# Submit an answer choice as a string below (eg. if you choose option A, put 'A')\n",
                "answer1 = '___'"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ‚è∏ Now set the `use_clip` to 1 and set a reasonable threshold, what do you observe?\n",
                "\n",
                "#### A. It still jumps away from the area of interest\n",
                "#### B. Solution stays in the area of interest and converges\n",
                "#### C. The solution doesn't not change\n",
                "#### D. The solution doesn't jump away from the area of interest but it does not converge"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_chow2) ###\n",
                "# Submit an answer choice as a string below (eg. if you choose option A, put 'A')\n",
                "answer2 = '___'"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ‚è∏ What would you have to do to make the previous solution converge?\n",
                "\n",
                "#### A. Increase the clipping threshold.\n",
                "#### B. Reduce the learning rate.\n",
                "#### C. Increase epsilon i.e. the convergence criteria.\n",
                "#### D. B or C."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_chow3) ###\n",
                "# Submit an answer choice as a string below (eg. if you choose option A, put 'A')\n",
                "answer3 = '___'"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Mindchow üç≤"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "After marking your exercise, try tweaking learning_rate, and perhaps the default value of clip_threshold. Can you anticipate how it will affect your results? \n",
                "\n",
                "See if you can find a combination that will converge to the global minimum."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_chow4) ###\n",
                "# Type your answer within in the quotes given\n",
                "answer4 = '___'"
            ]
        }
    ]
}
