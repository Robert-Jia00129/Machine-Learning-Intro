{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to compute response given predictor\n",
    "def f(x):\n",
    "    return np.cos(3*np.pi*x)/x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to compute the derivative\n",
    "def der_f(x):\n",
    "    return -(3*np.pi*x*np.sin(3*np.pi*x)+np.cos(3*np.pi*x))/x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function to get tangent points\n",
    "def get_tangent_line(x, x_range=.5):\n",
    "    y = f(x)\n",
    "    m = der_f(x)\n",
    "    x1, y1 = x, y\n",
    "    x = np.linspace(x1-x_range/2, x1+x_range/2, 50)\n",
    "    y = m*(x-x1)+y1\n",
    "    return x, y, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function to plot the data\n",
    "def plot_it(cur_x, title='', ax=plt):\n",
    "    y = f(x)\n",
    "    ax.plot(x,y)\n",
    "    ax.scatter(cur_x, f(cur_x), c='r', s=80, alpha=1);\n",
    "    x_tan, y_tan, der = get_tangent_line(cur_x)\n",
    "    ax.plot(x_tan, y_tan, ls='--', c='r')\n",
    "    # indicate when if our location is outside the x range\n",
    "    if cur_x > x.max():\n",
    "        ax.axvline(x.max(), c='r', lw=3)\n",
    "        ax.arrow(x.max()/1.6, y.max()/2, x.max()/5, 0, color='r', head_width=.25)\n",
    "    if cur_x < x.min():\n",
    "        ax.axvline(x.min(), c='r', lw=3)\n",
    "        ax.arrow(x.max()/2.5, y.max()/2, -x.max()/5, 0, color='r', head_width=.25)\n",
    "    ax.set_xlim(x.min(), x.max())\n",
    "    ax.set_ylim(-3.5, 3.5)\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 200 predictor data points between 0.1 and 3 using np.linspace\n",
    "x = ___\n",
    "\n",
    "# Get the response data from the predictor data by calling the function f \n",
    "y = ___\n",
    "\n",
    "# Helper code to plot the generated data\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "plt.plot(x,y, linewidth=3, color='#F5B7B1')\n",
    "plt.xlim(x.min(), x.max());\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel('$x$', fontsize=16)\n",
    "plt.ylabel('$y$', fontsize=16)\n",
    "plt.grid(alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to perform clipping\n",
    "# This function should retun the gradient with a magnitude <=clip_threshold\n",
    "\n",
    "def clip(g, clip_threshold=8):\n",
    "    \n",
    "    # Compare the absolute value of the gradient with the clip_threshold\n",
    "    ___\n",
    "        \n",
    "    # Compute the gradient based on the equation given\n",
    "    ___\n",
    "        \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the initial value of x\n",
    "cur_x = 0.5 \n",
    "\n",
    "# The learning rate for gradient descent\n",
    "learning_rate = 0.001\n",
    "\n",
    "# The decay rate determines the percent by which the learning rate reduces each step\n",
    "decay_rate = ___\n",
    "\n",
    "# Setting the epsilon value\n",
    "epsilon = 0.025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### â¸ What will happen if the decay rate is made extremely small, for example decay_rate=0.000001?\n",
    "\n",
    "#### A. The learning rate will reduce rapidly to become zero and thus each value would be the same as the previous.\n",
    "#### B. The learning rate will increase rapidly causing to jump over the minima.\n",
    "#### C. The learning rate will hardly change and hence would take the algorithm longer to converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_chow1) ###\n",
    "# Submit an answer choice as a string below (eg. if you choose option A, put 'A')\n",
    "answer1 = '___'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_clipping) ###\n",
    "fig, axs = plt.subplots(4,5, figsize=(15,6), sharey=True)\n",
    "\n",
    "\n",
    "for i, ax in enumerate(axs.ravel()):\n",
    "    plot_it(cur_x, title=f\"{i} step{'' if i == 1 else 's'}\", ax=ax)\n",
    "    \n",
    "    # Store the current x value before change in a separate variable\n",
    "    prev_x = ___\n",
    "    \n",
    "    # Compute the derivative of cur_x using the function der_f\n",
    "    der_cur_x = ___\n",
    "    \n",
    "    # Get the gradient of the derivative of x using clipping\n",
    "    g = ___\n",
    "\n",
    "    # Update the x-value using the learning rate\n",
    "    cur_x = ___\n",
    "    \n",
    "    # Update the learning rate based on the decay rate\n",
    "    learning_rate = ___\n",
    "    \n",
    "    # Stop algorithm if magnitude of change below epsilon\n",
    "    if np.abs(cur_x - prev_x) <= epsilon: \n",
    "        # hide unused subplots\n",
    "        for ax in axs.ravel()[i+1:]:\n",
    "            ax.axis('off') \n",
    "        break\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if i == len(axs.ravel())-1:\n",
    "    print('Did not converge!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mindchow ðŸ²"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After marking your exercise, try tweaking learning_rate, and perhaps the default value of clip_threshold. Can you anticipate how it will affect your results? \n",
    "\n",
    "See if you can find a combination that will converge to the global minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_chow2) ###\n",
    "# Type your answer within in the quotes given\n",
    "\n",
    "answer2 = '___'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
